"""LLM chat inference on a serverless GPU example."""

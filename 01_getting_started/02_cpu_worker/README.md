# CPU Worker: Serverless CPU Computing

Simple example demonstrating CPU-based serverless workers with automatic scaling on Runpod's infrastructure.

## Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Configure Environment

Create `.env` file:

```bash
RUNPOD_API_KEY=your_api_key_here
```

Get your API key from [Runpod Settings](https://www.runpod.io/console/user/settings).

### 3. Run Locally

```bash
flash run
```

Server starts at **http://localhost:8888**

### 4. Test the API

Visit **http://localhost:8888/docs** for interactive API documentation. QB endpoints are auto-generated by `flash run` based on your `@remote` functions.

```bash
curl -X POST http://localhost:8888/cpu_worker/run_sync \
  -H "Content-Type: application/json" \
  -d '{"name": "Flash User"}'
```

Visit **http://localhost:8000/docs** for interactive API documentation.

### Full CLI Documentation

For complete CLI usage including deployment, environment management, and troubleshooting:
- **[CLI Reference](../../CLI-REFERENCE.md)** - All commands and options
- **[Getting Started Guide](../../docs/cli/getting-started.md)** - Step-by-step tutorial
- **[Workflows](../../docs/cli/workflows.md)** - Common development patterns

## What This Demonstrates

### CPU Worker (`cpu_worker.py`)

Simple CPU-based serverless function that:
- Processes requests without GPU overhead
- Returns system and platform information
- Scales from 0-3 workers automatically
- Runs on general-purpose CPU instances

The worker demonstrates:
- Remote execution with `@remote` decorator
- CPU resource configuration with `CpuLiveServerless`
- Automatic scaling based on demand
- Lightweight API request handling

## API Endpoints

QB (queue-based) endpoints are auto-generated from `@remote` functions. Visit `/docs` for the full API schema.

### `cpu_hello`

Executes a simple CPU worker and returns a greeting with system information.

**Request:**
```json
{
  "name": "Flash User"
}
```

**Response:**
```json
{
  "status": "success",
  "message": "Hello, Flash User!",
  "worker_type": "CPU",
  "timestamp": "2024-01-24T10:30:45.123456",
  "platform": "Linux",
  "python_version": "3.11.0"
}
```

## Project Structure

```
02_cpu_worker/
├── cpu_worker.py        # CPU worker with @remote decorator
├── pyproject.toml       # Project metadata
├── requirements.txt     # Dependencies
├── .env.example         # Environment variables template
└── README.md            # This file
```

## Key Concepts

### Remote Execution
The `@remote` decorator transparently executes functions on serverless infrastructure:
- Code runs locally during development
- Automatically deploys to Runpod when configured
- Handles serialization and resource management

### Resource Scaling
The CPU worker scales to zero when idle:
- **workersMin=0**: Scales down completely when idle
- **workersMax=3**: Up to 3 concurrent workers
- **idleTimeout=5**: 5 minutes before scaling down

### CPU Instance Types
Available CPU configurations:
- `CpuInstanceType.CPU3G_2_8`: 2 vCPU, 8GB RAM (General Purpose)
- `CpuInstanceType.CPU3C_4_8`: 4 vCPU, 8GB RAM (Compute Optimized)
- `CpuInstanceType.CPU5G_4_16`: 4 vCPU, 16GB RAM (Latest Gen)

## Development

### Test Worker Locally
```bash
python cpu_worker.py
```

### Run the Application
```bash
flash run
```

## When to Use CPU Workers

Choose CPU workers for:
- API request handling
- Data processing and transformation
- Lightweight compute tasks
- Cost-sensitive workloads
- No GPU requirements

Compare with GPU workers when you need:
- Machine learning inference
- Image/video processing
- CUDA acceleration
- GPU-specific libraries (PyTorch, TensorFlow)

## Next Steps

- Customize CPU type: Change `CpuInstanceType.CPU3G_2_8` to specific instance type
- Add request validation and error handling
- Integrate with databases or external APIs
- Deploy to production with `flash deploy`

## Resources

- [Flash Documentation](https://docs.runpod.io/flash)
- [Runpod API Documentation](https://docs.runpod.io/api)
- [CPU Instance Types Reference](https://docs.runpod.io/pods/api-reference/pod-instance-types)
